{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = '../input/pytorch-image-models/pytorch-image-models-master'\n",
    "\n",
    "import sys\n",
    "sys.path.append(package_path)\n",
    "\n",
    "DATA_DIR = '../input/cassava-leaf-disease-classification'\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import timm\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'vit_base_patch16_384',\n",
    "    'img_size': 384,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 32,\n",
    "    'valid_bs': 16,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 1, # support to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 4,\n",
    "    'weights': [1] * 10\n",
    "}\n",
    "\n",
    "model_path_vit = []\n",
    "model_path_eff = []\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, transforms=None, output_label=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['label']\n",
    "          \n",
    "        img  = get_img(f\"{self.data_root}/{self.df.loc[index]['image_id']}\")\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "def get_inference_transforms_vit():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(384, 384),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_inference_transforms_eff():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(512, 512),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "\n",
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        if 'vit' not in model_arch:\n",
    "            n_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        else:\n",
    "            n_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(n_features, n_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def inference_one_epoch(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    image_preds_all = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "    for step, (imgs) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        \n",
    "        image_preds = model(imgs)\n",
    "        image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        \n",
    "    image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "    return image_preds_all\n",
    "\n",
    "\n",
    "print(f'Inference fold started')\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['image_id'] = list(os.listdir(f'{DATA_DIR}/test_images/'))\n",
    "test_ds = CassavaDataset(\n",
    "    test, f'{DATA_DIR}/test_images/',\n",
    "    transforms=get_inference_transforms_vit(), output_label=False)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=CFG['valid_bs'],\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "\n",
    "device = torch.device(CFG['device'])\n",
    "\n",
    "\n",
    "tst_preds = []\n",
    "\n",
    "for i in range(len(model_path_vit)):\n",
    "    if 'large' in model_path_vit[i]:\n",
    "        model = CassvaImgClassifier('vit_large_patch16_384', 5).to(device)\n",
    "    else:\n",
    "        model = CassvaImgClassifier('vit_base_patch16_384', 5).to(device)\n",
    "\n",
    "    model.load_state_dict(\n",
    "        torch.load(model_path_vit[i]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sum_weights = sum(CFG['weights'])\n",
    "        for _ in range(CFG['tta']):\n",
    "            tst_image_preds = inference_one_epoch(model, tst_loader, device)\n",
    "            tst_preds += [CFG['weights'][i] / sum_weights / CFG['tta']*tst_image_preds]        \n",
    "\n",
    "test_ds = CassavaDataset(\n",
    "    test, f'{DATA_DIR}/test_images/',\n",
    "    transforms=get_inference_transforms_eff(), output_label=False)\n",
    "\n",
    "tst_loader = torch.utils.data.DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=CFG['valid_bs'] * 2,\n",
    "    num_workers=CFG['num_workers'],\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "            \n",
    "for i in range(len(model_path_eff)):            \n",
    "    if 'b5' in model_path_eff[i]:\n",
    "        model = CassvaImgClassifier('tf_efficientnet_b5_ns', 5).to(device)\n",
    "    else:\n",
    "        model = CassvaImgClassifier('tf_efficientnet_b4_ns', 5).to(device)\n",
    "        \n",
    "    model.load_state_dict(\n",
    "        torch.load(model_path_eff[i]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sum_weights = sum(CFG['weights'])\n",
    "        for _ in range(CFG['tta']):\n",
    "            tst_image_preds = inference_one_epoch(model, tst_loader, device)\n",
    "            tst_preds += [CFG['weights'][i] / sum_weights / CFG['tta']*tst_image_preds]   \n",
    "            \n",
    "tst_preds = np.mean(tst_preds, axis=0) \n",
    "\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "test['label'] = np.argmax(tst_preds, axis=1)\n",
    "test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
