{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py --version 1.7\n",
    "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.data_parallel as dp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.utils.serialization as xser\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import sys; \n",
    "package_paths = [\n",
    "    '../input/pytorch-image-models/pytorch-image-models-master', #'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\n",
    "    '../input/image-fmix/FMix-master'\n",
    "]\n",
    "for pth in package_paths:\n",
    "    sys.path.append(pth)\n",
    "    \n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "import scipy as sp\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "from albumentations import Compose, Normalize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    ")\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from fmix import sample_mask, make_low_freq_image, binarise_mask\n",
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import sklearn\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_USE_BF16\"] = \"1\"\n",
    "os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 5,\n",
    "    'seed': 2020,\n",
    "    'model_arch': 'vit_base_patch16_384',\n",
    "    'img_size': 384,\n",
    "    'epochs': 10,\n",
    "    'train_bs': 10,\n",
    "    'valid_bs': 10,\n",
    "    'T_0': 10,\n",
    "    'lr': 1e-4,\n",
    "    'min_lr': 1e-4,\n",
    "    'smoothing' : 0.06,\n",
    "    't1' : 0.8,\n",
    "    't2' : 1.4,\n",
    "    'warmup_factor' : 7,\n",
    "    'warmup_epo' : 1,\n",
    "    'num_workers': 8,\n",
    "    'accum_iter': 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(path)\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    return im_rgb\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, df, data_root, \n",
    "                 transforms=None, \n",
    "                 output_label=True, \n",
    "                 one_hot_label=False,\n",
    "                 do_fmix=False, \n",
    "                 fmix_params={\n",
    "                     'alpha': 1., \n",
    "                     'decay_power': 3., \n",
    "                     'shape': (CFG['img_size'], CFG['img_size']),\n",
    "                     'max_soft': True, \n",
    "                     'reformulate': False\n",
    "                 },\n",
    "                 do_cutmix=False,\n",
    "                 cutmix_params={\n",
    "                     'alpha': 1,\n",
    "                 }\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.do_fmix = do_fmix\n",
    "        self.fmix_params = fmix_params\n",
    "        self.do_cutmix = do_cutmix\n",
    "        self.cutmix_params = cutmix_params\n",
    "        \n",
    "        self.output_label = output_label\n",
    "        self.one_hot_label = one_hot_label\n",
    "        \n",
    "        if output_label == True:\n",
    "            self.labels = self.df['label'].values\n",
    "\n",
    "            if one_hot_label is True:\n",
    "                self.labels = np.eye(self.df['label'].max()+1)[self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.labels[index]\n",
    "          \n",
    "        img  = get_img(\"{}/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        \n",
    "        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            with torch.no_grad():\n",
    "                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n",
    "                \n",
    "                # Make mask, get mean / std\n",
    "                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n",
    "                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n",
    "    \n",
    "                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                fmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image_id']))\n",
    "\n",
    "                if self.transforms:\n",
    "                    fmix_img = self.transforms(image=fmix_img)['image']\n",
    "\n",
    "                mask_torch = torch.from_numpy(mask)\n",
    "                \n",
    "                # mix image\n",
    "                img = mask_torch*img+(1.-mask_torch)*fmix_img\n",
    "\n",
    "                rate = mask.sum()/CFG['img_size']/CFG['img_size']\n",
    "                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n",
    "       \n",
    "        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n",
    "            with torch.no_grad():\n",
    "                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n",
    "                cmix_img  = get_img(\"{}/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image_id']))\n",
    "                if self.transforms:\n",
    "                    cmix_img = self.transforms(image=cmix_img)['image']\n",
    "                    \n",
    "                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n",
    "\n",
    "                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (CFG['img_size'] * CFG['img_size']))\n",
    "                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n",
    "                      \n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),         \n",
    "            CoarseDropout(p=0.5),\n",
    "            Cutout(p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(df, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/'):\n",
    "    \n",
    "    from catalyst.data.sampler import BalanceClassSampler\n",
    "    \n",
    "    train_ = df.loc[trn_idx,:].reset_index(drop=True)\n",
    "    valid_ = df.loc[val_idx,:].reset_index(drop=True)\n",
    "        \n",
    "    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True, one_hot_label=False, do_fmix=0, do_cutmix=0)\n",
    "    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n",
    "    \n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_ds,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True)\n",
    "\n",
    "\n",
    "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        valid_ds,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False,\n",
    "        )\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=CFG['train_bs'],\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_ds,\n",
    "        batch_size=CFG['valid_bs'],\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=CFG['num_workers'],\n",
    "    )\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u'.\"\"\"\n",
    "    if t==1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u'.\"\"\"\n",
    "    if t==1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same shape as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "                exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                logt_partition.pow(1.0-t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t < 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (< 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower)/2.0\n",
    "        sum_probs = torch.sum(\n",
    "                exp_t(normalized_activations - logt_partition, t),\n",
    "                dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "                lower * update + (1.0-update) * logt_partition,\n",
    "                shape_partition)\n",
    "        upper = torch.reshape(\n",
    "                upper * (1.0 - update) + update * logt_partition,\n",
    "                shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower)/2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t=t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants \n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "        \n",
    "        return grad_input, None, None\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example. \n",
    "    Backward pass is implemented.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters = 5):\n",
    "    \"\"\"Tempered sigmoid function.\n",
    "    Args:\n",
    "      activations: Activations for the positive class for binary classification.\n",
    "      t: Temperature tensor > 0.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature > 1.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing = 0.0,\n",
    "        num_iters=5,\n",
    "        reduction='mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered binary logistic loss.\n",
    "    Args:\n",
    "      activations: A tensor containing activations for class 1.\n",
    "      labels: A tensor with shape as activations, containing probabilities for class 1\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "        1.0 - labels.to(activations.dtype)],\n",
    "        dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations, \n",
    "            internal_labels,\n",
    "            t1,\n",
    "            t2,\n",
    "            label_smoothing = label_smoothing,\n",
    "            num_iters = num_iters,\n",
    "            reduction = reduction)\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n",
    "    model.train()\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()\n",
    "\n",
    "        with autocast():\n",
    "            image_preds = model(imgs)\n",
    "            loss = bi_tempered_logistic_loss(image_preds, image_labels, t1=CFG['t1'], t2=CFG['t2'], label_smoothing=CFG['smoothing'])     \n",
    "            loss.backward()\n",
    "\n",
    "            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n",
    "                xm.optimizer_step(optimizer)\n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                if scheduler is not None and schd_batch_update:\n",
    "                    scheduler.step()\n",
    "\n",
    "          \n",
    "    if scheduler is not None and not schd_batch_update:\n",
    "        scheduler.step()\n",
    "        \n",
    "def valid_one_epoch(epoch, model, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    loss_sum = 0\n",
    "    sample_num = 0\n",
    "    image_preds_all = []\n",
    "    image_targets_all = []\n",
    "\n",
    "    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "    for step, (imgs, image_labels) in pbar:\n",
    "        imgs = imgs.to(device).float()\n",
    "        image_labels = image_labels.to(device).long()      \n",
    "        image_preds = model(imgs)  \n",
    "        xm.mark_step()\n",
    "        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n",
    "        image_targets_all += [image_labels.detach().cpu().numpy()]\n",
    "\n",
    "        loss = bi_tempered_logistic_loss(image_preds, image_labels, t1=CFG['t1'], t2=CFG['t2'], label_smoothing=CFG['smoothing'])\n",
    "\n",
    "    image_preds_all = np.concatenate(image_preds_all)\n",
    "    image_targets_all = np.concatenate(image_targets_all)\n",
    "    acc = (image_preds_all==image_targets_all).mean()\n",
    "    accuracy = xm.mesh_reduce('test_accuracy', acc, np.mean)\n",
    "    xm.master_print(\"Validation Accuracy = \",accuracy)\n",
    "   \n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.head.in_features\n",
    "        self.model.head = nn.Linear(n_features, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)         \n",
    "    for fold, (trn_idx, val_idx) in enumerate(folds):\n",
    "\n",
    "        model = CassvaImgClassifier(CFG['model_arch'], train.label.nunique(), pretrained=True)\n",
    "        device = xm.xla_device()\n",
    "        model.to(device)\n",
    "        print(fold)\n",
    "        train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/')\n",
    "        \n",
    "        lr =  CFG['lr']* xm.xrt_world_size()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr/CFG['warmup_factor'])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n",
    "\n",
    "        #save best epoch of each fold\n",
    "        best_accuracy = 0.0\n",
    "        \n",
    "        for epoch in range(CFG['epochs']):\n",
    "            gc.collect()\n",
    "            para_loader = pl.ParallelLoader(train_loader, [device])\n",
    "            train_one_epoch(epoch, model, optimizer, para_loader.per_device_loader(device), device, scheduler=scheduler, schd_batch_update=False)\n",
    "\n",
    "            del para_loader\n",
    "            gc.collect()\n",
    "            para_loader = pl.ParallelLoader(val_loader, [device])\n",
    "            val_loss,cur_accuracy = valid_one_epoch(epoch, model, para_loader.per_device_loader(device), device)\n",
    "\n",
    "            del para_loader\n",
    "            gc.collect()\n",
    "\n",
    "            content = time.ctime() + ' ' + f'FOLD -> {fold} --> Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val_loss : {(val_loss):.5f},Validation_Accuracy: {(cur_accuracy):.5f}'\n",
    "\n",
    "            with open(f'log.txt', 'a') as appender:\n",
    "                appender.write(content + '\\n')\n",
    "       \n",
    "            if cur_accuracy > best_accuracy:\n",
    "                xm.save(model.state_dict(),'{}_fold_{}_best_epoch'.format(CFG['model_arch'], fold))\n",
    "                best_accuracy = cur_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def _mp_fn(rank, flags):\n",
    "    global acc_list\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    res = train_model()\n",
    "\n",
    "FLAGS={}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
